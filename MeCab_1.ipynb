{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeCabの使用法\n",
    "\n",
    "MeCab の文字コードはデフォルトで EUC-JP だが、Python から呼び出す利便性を考え、UTF-8 に統一しておくとよい\n",
    "\n",
    "インストール方法\n",
    "\n",
    "$ brew install mecab\n",
    "$ brew install mecab-ipadic\n",
    "\n",
    "mecab-ipadic-NEologdをインストールします。\n",
    "これはWeb上の新語をデフォルトの辞書に追加したものです。\n",
    "必須ではありませんが便利なので入れておきます。\n",
    "\n",
    "$ brew install git curl xz\n",
    "$ git clone --depth 1 git@github.com:neologd/mecab-ipadic-neologd.git\n",
    "$ cd mecab-ipadic-neologd\n",
    "$ ./bin/install-mecab-ipadic-neologd -n\n",
    "\n",
    "次にpipでmecab-python3をインストールします。\n",
    "$ pip install mecab-python3\n",
    "\n",
    "MeCab.Taggerで指定するパスは\n",
    "$ echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"\n",
    "で調べられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mc.Tagger()で、オプションがデフォルトのケース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毎日\t名詞,副詞可能,*,*,*,*,毎日,マイニチ,マイニチ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "学校\t名詞,一般,*,*,*,*,学校,ガッコウ,ガッコー\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "行き\t動詞,自立,*,*,五段・カ行促音便,連用形,行く,イキ,イキ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "明日\t名詞,副詞可能,*,*,*,*,明日,アシタ,アシタ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "風邪\t名詞,一般,*,*,*,*,風邪,カゼ,カゼ\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "休み\t動詞,自立,*,*,五段・マ行,連用形,休む,ヤスミ,ヤスミ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "sentence =\"毎日、私は学校に行きます。明日は、風邪で休みます。\"\n",
    "mc=MeCab\n",
    "tagger= mc.Tagger()\n",
    "print (tagger.parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、コンストラクタに -Ochasen オプションを与えることにより、ChaSen 形式で出力している。 MeCab.Tagger#parse() で、入力文を解析して出力を文字列として受け取ることができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "気温\t名詞,一般,*,*,*,*,気温,キオン,キオン\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "上がる\t動詞,自立,*,*,五段・ラ行,基本形,上がる,アガル,アガル\n",
      "と\t助詞,接続助詞,*,*,*,*,と,ト,ト\n",
      "どうしても\t副詞,一般,*,*,*,*,どうしても,ドウシテモ,ドーシテモ\n",
      "比例\t名詞,サ変接続,*,*,*,*,比例,ヒレイ,ヒレイ\n",
      "する\t動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
      "の\t名詞,非自立,一般,*,*,*,の,ノ,ノ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "電力\t名詞,一般,*,*,*,*,電力,デンリョク,デンリョク\n",
      "使用\t名詞,サ変接続,*,*,*,*,使用,シヨウ,シヨー\n",
      "量\t名詞,接尾,一般,*,*,*,量,リョウ,リョウ\n",
      "だ\t助動詞,*,*,*,特殊・ダ,基本形,だ,ダ,ダ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "９\t名詞,数,*,*,*,*,９,キュウ,キュー\n",
      "日\t名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "全国\t名詞,一般,*,*,*,*,全国,ゼンコク,ゼンコク\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "電力\t名詞,一般,*,*,*,*,電力,デンリョク,デンリョク\n",
      "会社\t名詞,一般,*,*,*,*,会社,カイシャ,カイシャ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "うち\t名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ\n",
      "８\t名詞,数,*,*,*,*,８,ハチ,ハチ\n",
      "社\t名詞,接尾,助数詞,*,*,*,社,シャ,シャ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "管内\t名詞,一般,*,*,*,*,管内,カンナイ,カンナイ\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "いずれ\t名詞,代名詞,一般,*,*,*,いずれ,イズレ,イズレ\n",
      "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "最大\t名詞,一般,*,*,*,*,最大,サイダイ,サイダイ\n",
      "電力\t名詞,一般,*,*,*,*,電力,デンリョク,デンリョク\n",
      "使用\t名詞,サ変接続,*,*,*,*,使用,シヨウ,シヨー\n",
      "量\t名詞,接尾,一般,*,*,*,量,リョウ,リョウ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "今夏\t名詞,副詞可能,*,*,*,*,今夏,コンカ,コンカ\n",
      "最高\t名詞,一般,*,*,*,*,最高,サイコウ,サイコー\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "記録\t名詞,サ変接続,*,*,*,*,記録,キロク,キロク\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "mecab = MeCab.Tagger()\n",
    "sent =\"気温が上がるとどうしても比例するのが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。\"\n",
    "\n",
    "print (mecab.parse(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "気温が上がるとどうしても比例するのが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,気温,キオン,キオン\n",
      " 助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      " 動詞,自立,*,*,五段・ラ行,基本形,上がる,アガル,アガル\n",
      "とどうしても比例するのが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 助詞,接続助詞,*,*,*,*,と,ト,ト\n",
      "どうしても比例するのが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 副詞,一般,*,*,*,*,どうしても,ドウシテモ,ドーシテモ\n",
      "比例するのが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,サ変接続,*,*,*,*,比例,ヒレイ,ヒレイ\n",
      "するのが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
      "のが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,非自立,一般,*,*,*,の,ノ,ノ\n",
      "が電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,電力,デンリョク,デンリョク\n",
      "使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,サ変接続,*,*,*,*,使用,シヨウ,シヨー\n",
      "量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,接尾,一般,*,*,*,量,リョウ,リョウ\n",
      "だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 助動詞,*,*,*,特殊・ダ,基本形,だ,ダ,ダ\n",
      "。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 記号,句点,*,*,*,*,。,。,。\n",
      "９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,数,*,*,*,*,９,キュウ,キュー\n",
      "日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ\n",
      "は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 記号,読点,*,*,*,*,、,、,、\n",
      "全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,全国,ゼンコク,ゼンコク\n",
      "の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,電力,デンリョク,デンリョク\n",
      "会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,会社,カイシャ,カイシャ\n",
      "のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "うち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ\n",
      "８社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,数,*,*,*,*,８,ハチ,ハチ\n",
      "社の管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,接尾,助数詞,*,*,*,社,シャ,シャ\n",
      "の管内で、いずれも最大電力使用量が今夏最高を記録した。 助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "管内で、いずれも最大電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,管内,カンナイ,カンナイ\n",
      "で、いずれも最大電力使用量が今夏最高を記録した。 助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "、いずれも最大電力使用量が今夏最高を記録した。 記号,読点,*,*,*,*,、,、,、\n",
      "いずれも最大電力使用量が今夏最高を記録した。 名詞,代名詞,一般,*,*,*,いずれ,イズレ,イズレ\n",
      "も最大電力使用量が今夏最高を記録した。 助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "最大電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,最大,サイダイ,サイダイ\n",
      "電力使用量が今夏最高を記録した。 名詞,一般,*,*,*,*,電力,デンリョク,デンリョク\n",
      "使用量が今夏最高を記録した。 名詞,サ変接続,*,*,*,*,使用,シヨウ,シヨー\n",
      "量が今夏最高を記録した。 名詞,接尾,一般,*,*,*,量,リョウ,リョウ\n",
      "が今夏最高を記録した。 助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "今夏最高を記録した。 名詞,副詞可能,*,*,*,*,今夏,コンカ,コンカ\n",
      "最高を記録した。 名詞,一般,*,*,*,*,最高,サイコウ,サイコー\n",
      "を記録した。 助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "記録した。 名詞,サ変接続,*,*,*,*,記録,キロク,キロク\n",
      "した。 動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "た。 助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
      "。 記号,句点,*,*,*,*,。,。,。\n",
      " BOS/EOS,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "mecab = MeCab.Tagger('-Ochasen')\n",
    "sentence =\"気温が上がるとどうしても比例するのが電力使用量だ。９日は、全国の電力会社のうち８社の管内で、いずれも最大電力使用量が今夏最高を記録した。\"\n",
    "\n",
    "node = mecab.parseToNode(sentence)\n",
    "node = node.next\n",
    "\n",
    "while node:\n",
    "        print (node.surface, node.feature)\n",
    "        node = node.next\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Taggerのオプションが分かち書き"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毎日 、 私 は 学校 に 行き ます 。 明日 は 、 風邪 で 休み ます 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import MeCab\n",
    "mecab = MeCab.Tagger('-Owakati')\n",
    "sent =\"毎日、私は学校に行きます。明日は、風邪で休みます。\"\n",
    "print (mecab.parse(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毎日、私は学校に行きます。明日は、風邪で休みます。 名詞,副詞可能,*,*,*,*,毎日,マイニチ,マイニチ\n",
      "、私は学校に行きます。明日は、風邪で休みます。 記号,読点,*,*,*,*,、,、,、\n",
      "私は学校に行きます。明日は、風邪で休みます。 名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
      "は学校に行きます。明日は、風邪で休みます。 助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "学校に行きます。明日は、風邪で休みます。 名詞,一般,*,*,*,*,学校,ガッコウ,ガッコー\n",
      "に行きます。明日は、風邪で休みます。 助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "行きます。明日は、風邪で休みます。 動詞,自立,*,*,五段・カ行促音便,連用形,行く,イキ,イキ\n",
      "ます。明日は、風邪で休みます。 助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。明日は、風邪で休みます。 記号,句点,*,*,*,*,。,。,。\n",
      "明日は、風邪で休みます。 名詞,副詞可能,*,*,*,*,明日,アシタ,アシタ\n",
      "は、風邪で休みます。 助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、風邪で休みます。 記号,読点,*,*,*,*,、,、,、\n",
      "風邪で休みます。 名詞,一般,*,*,*,*,風邪,カゼ,カゼ\n",
      "で休みます。 助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "休みます。 動詞,自立,*,*,五段・マ行,連用形,休む,ヤスミ,ヤスミ\n",
      "ます。 助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。 記号,句点,*,*,*,*,。,。,。\n",
      " BOS/EOS,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "sentence =\"毎日、私は学校に行きます。明日は、風邪で休みます。\"\n",
    "mecab = MeCab.Tagger()\n",
    "mecab.parseToNode('')\n",
    "node = mecab.parseToNode(sentence)\n",
    "node = node.next\n",
    "while node:\n",
    "    print (node.surface, node.feature)\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parseToNode() メソッドは、解析結果をノードの双方向連結リストとして受け取る。 node.next と node.prev でノードを順方向または逆方向にたどることができる。 surface は単語そのもの、 feature は素性を文字列として表したものであり、この場合、素性は「品詞1, 品詞2, 品詞3, 品詞4, 活用型, 活用系, 活用形, 読み, 発音」という構造をしている。なお、このリストの先頭および末尾は、それぞれ BOS 、 EOS 、すなわち文頭、文末を示す特殊なノードである。この例では、先頭はスキップしている。\n",
    "また、トークナイザの1つとしてこの MeCab の Python バインディングのラッパーである JPMeCabTokenizer を用意しており、コーパスを読み込む際のトークン化に使うことができる。使い方は先の JPSimpleTokenizer と同様である"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mecab-ipadic-NEologdを使用する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "毎日、私は学校に行きます。明日は、風邪で休みます。 BOS/EOS\n",
      "毎日、私は学校に行きます。明日は、風邪で休みます。 名詞\n",
      "、私は学校に行きます。明日は、風邪で休みます。 記号\n",
      "私は学校に行きます。明日は、風邪で休みます。 名詞\n",
      "は学校に行きます。明日は、風邪で休みます。 助詞\n",
      "学校に行きます。明日は、風邪で休みます。 名詞\n",
      "に行きます。明日は、風邪で休みます。 助詞\n",
      "行きます。明日は、風邪で休みます。 動詞\n",
      "ます。明日は、風邪で休みます。 助動詞\n",
      "。明日は、風邪で休みます。 記号\n",
      "明日は、風邪で休みます。 名詞\n",
      "は、風邪で休みます。 助詞\n",
      "、風邪で休みます。 記号\n",
      "風邪で休みます。 名詞\n",
      "で休みます。 助詞\n",
      "休みます。 動詞\n",
      "ます。 助動詞\n",
      "。 記号\n",
      " BOS/EOS\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "mecab = MeCab.Tagger ('-Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "\n",
    "text =\"毎日、私は学校に行きます。明日は、風邪で休みます。\"\n",
    "\n",
    "mecab.parse('')#文字列がGCされるのを防ぐ\n",
    "node = mecab.parseToNode(text)\n",
    "while node:\n",
    "    #単語を取得\n",
    "    word = node.surface\n",
    "    #品詞を取得\n",
    "    pos = node.feature.split(\",\")[0]\n",
    "    print (word, pos)\n",
    "    #print('{0} , {1}'.format(word, pos))\n",
    "    #次の単語に進める\n",
    "    node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メロス は 激怒 し た 。 必ず 、 かの 邪智 暴虐 の 王 を 除か なけれ ば なら ぬ と 決意 し た 。 メロス に は 政治 が わから ぬ 。 メロス は 、 村 の 牧人 で ある 。 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "sentence = 'メロスは激怒した。必ず、かの邪智暴虐の王を除かなければならぬと決意した。メロスには政治がわからぬ。メロスは、村の牧人である。'\n",
    "#分かち書き\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "text = tagger.parse(sentence)\n",
    "print(text, \"\\n\")\n",
    "\n",
    "with open('./corpora/text.txt', mode='w') as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アサヒ 飲料 は 4 月 下旬 から 、 凍る 直前 の マイナス 5 ℃ まで 冷やし た 『 三ツ矢 サイダー 』 を 提供 する “ 氷点下 自販機 ” を 全国 で 展開 中 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "\n",
    "text = 'アサヒ飲料は4月下旬から、凍る直前のマイナス5℃まで冷やした『三ツ矢サイダー』を提供する“氷点下自販機”を全国で展開中。'\n",
    "tagger = MeCab.Tagger ('-Owakati')\n",
    "result = tagger.parse(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アサヒ飲料 は 4月下旬 から 、 凍る 直前 の マイナス 5℃ まで 冷やし た 『 三ツ矢サイダー 』 を 提供 する “ 氷点下 自販機 ” を 全国 で 展開 中 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "\n",
    "text = 'アサヒ飲料は4月下旬から、凍る直前のマイナス5℃まで冷やした『三ツ矢サイダー』を提供する“氷点下自販機”を全国で展開中。'\n",
    "tagger = MeCab.Tagger ('-Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "result = tagger.parse(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "冒頭 に お話 し いただい た 「 AI ってな ん でも できる 夢 の よう な 技術 」 という イメージ から 抜け出す ため に 参加 し まし た 。 午前 の 座 学 が 大変 わかり やすく 、 午後 の work で さらに 理解 を 深める こと が でき まし た 。 途中 、 数学 の お話 が 濃く なっ た 時 は 焦り まし た が 。 。 。 やり たい こと に対する 事例 ・ アドバイス が 聞ける サービス 目 線 の セミナー が あり まし たら ぜひ 参加 し たい です 。 これ まで 様々 な セミナー に 参加 し て き まし た が 、 個人 的 に 一番 満足 でき た セミナー でし た 。 自分 史上 最高 の セミナー でし た 。 プログラミング 関係 に 疎い 私 でも 理解 でき 、 逆 に プログラミング に 興味 を 持ち 、 自分 で も プログラミング に 携わり たい ・ 作り たい と 思い まし た 。 今後 、 弊社 において 、 AI 技術 を 活用 し た システム の 開発 及び サービス の 提供 を 進め て いく うえ で 、 どの よう な 準備 が 必要 な の か 、 どの よう な サービス を 提供 できる の か を 確認 する こと が でき まし た 。 講師 の 皆様 は 、 非常 に わかり やすく 、 親切 丁寧 に ご 教示 ください まし た 。 今後 、 プログラミング 等 の セミナー に も 参加 さ せ て いただき たく 思い ます 。 ありがとう ござい まし た 。 AI の 仕組み が とても 良く 理解 でき た 。 講義 内容 も 丁寧 で 面白く 、 長時間 で あっ た が 飽きる こと なく 終わる こと が 出来 た 。 入門 という 事 で ある が 、 十分 に ｄｅｅｐ な 内容 で 、 AI の 可能 性 を 示唆 し て くれる 内容 だっ た 。 持ち込ん だ パソコン で トラブル が 発生 し た が 、 予備 機 を 貸し出し て くださ り 感謝 し て い ます 。 今回 、 サプライズ 講師 の 小池 氏 の 講義 は 興味深く 感銘 を 受け た 。 特に 「 AI の 民主 化 」 という キーワード に 刺激 を 受け 、 何 か 出来 ない か と 考え を 巡らし 始める きっかけ を 貰う こと が 出来 た 。 休憩 時間 など で 、 スタッフ へ の 質問 に も 丁寧 に 答え て 頂き 、 対応 も 良かっ た です 。 時間 を 忘れる ほど 楽しい 経験 が でき た 。 小池 さん の 生 の 開発 話 が 大変 興味深かっ た 。 クレジットカード 審査 など は 、 AI を 使わ なく て も できる の で は ？ と 思い どの よう な 問題 を AI を 使っ て 解決 すれ ば よい の か 、 おぼろ げ ながら イメージ できる よう に なり まし た 。 セミナー に 参加 する こと により 、 自分 の Ａ Ｉ の イメージ が 正しい の か どう な の か を ある程度 、 把握 する こと が でき まし た 。 画像 判別 の 手法 は 漠然と し た もの だっ た の です が 、 今回 の セミナー で なんとなく イメージ でき た よう な 気 が し ます 。 AzureML も 実際 に 操作 する こと により 、 重たかっ た 扉 が 開き 、 少し 先 へ 進ん で みよ う と 思える よう に なり まし た 。 ＡＩ を より 深く 勉強 し て いく ため の きっかけ を 与え て くれる 入門 編 として は よかっ た と 思い ます 。 自宅 から 遠かっ た ので 迷っ た の です が 受講 し て 本当に 良かっ た 。 次回 も 受け たい ので ご 案内 お願い し ます 。 今回 は 「 AI 入門 」 という こと で 、 漠然と しか 知ら なかっ た AI に対して バックボーン の 技術 や 、 AzureML で の 実装 など を 学ぶ こと で 、 より 具体 的 な もの と なっ た ので 良かっ た です 。 ただ 、 AI に関する 知識 が 具体 的 に なっ た 反面 、 もっと 詳細 に 知り たい と 思う 内容 が 増え て しまい まし た 。 （ けっして 悪い と 言っ て いる わけ で は あり ませ ん ） なんとなく 理解 し て い た 人工 知能 、 AI 、 機械 学習 の 意味 が より 理解 でき た と 思い まし た 。 わかり やすく ありがとう ござい まし た 。 これ で 終わっ て しまっ て も もったいない ので ぜひ 続編 を お願い し たい と 思い ます 。 説明 者 以外 の 方 が い て 頂い た 事 で 質問 し やすかっ た です し 理解 も 出来 まし た 。 説明 は 分かり やすく 、 資料 も 整っ て おり 、 操作 も 一 通り 出来 た ので 、 全般 的 に は 大変 良かっ た です 。 AI について は 、 なんとなく キーワード は よく 聞く だけ で 、 どういう もの か が わかっ て い なかっ た です が 、 セミナー に 参加 する こと で AI の 仕組み について わかり やすく 説明 を し て もらえ た ので 、 どういう もの が できる か の イメージ が できる よう に なり まし た 。 Azure ML を 使用 する こと で 、 AI も 実際 に 作成 でき 楽しく セミナー に 参加 でき まし た 。 ありがとう ござい まし た 。 難しい よう に 見え ます が 仕組み は 簡単 に つくれる 環境 が あっ て 誰 でも できる ところ が 素晴らしい と 思い まし た 。 また 、 それ を 活用 し やすい よう に 解説 さ れ て 題材 も 提供 さ れ て いる ので わかり やすく て 面白かっ た です 。 AI に関して 全く 知識 が 無く 、 漠然と し て い まし た が 、 この セミナー を 受け て 少し 霧 が 晴れ た 気 が する と 同時に 、 AI へ の 興味 が 強く なり まし た 。 ありがとう ござい まし た 。 初めて 人工 知能 の セミナー に 参加 し まし た が 、 とても わかり やすい 内容 でし た 。 今回 は 大変 勉強 に なり まし た 。 ありがとう ござい まし た 。 午後 の 内容 が とっ かかり として 非常 に よかっ た ので 、 より 具体 的 な 課題 に対する 実習 主体 の コース が でき たら また 参加 し たい と 思い ます 。 まさか 自分 が 人工 知能 を 作れる 日 が 来る と は 思っ て も い なかっ た ので 大変 満足 し て い ます 。 例え が 分かり やすく 、 人工 知能 や 機械 学習 の 仕組み について も 理解 する こと が でき まし た 。 大変 興味深く 拝聴 いたし まし た 。 知識 が まったく ゼロ の 状態 から 、 AI の 基本 的 な 仕組み の 理解 と DeepLearning による 画像 認識 AI の 作成 まで でき て 驚い て い ます 。 非常 に 効率 的 で わかり やすい 説明 に 感謝 し て おり ます 。 azure ml など の サービス で 機械 学習 が 簡単 に 組める の を 知り 、 時代 の 流れ の 速 さ に 驚き まし た 。 昨今 AI 関連 の セミナ は 多数 開催 さ れ て おり 、 玉石混交 の 感 が あり ます が 、 実際 に 作成 する タイプ は 斬新 でし た 。 かつ 、 適度 に 既 製品 を 使っ て 作成 する ため 、 プログラミング の 専門 知識 が なく て も 、 AI の 作成 プロセス が 仮想 体験 でき まし た 。 1 日 で ここ まで AI を 理解 できる と は 思い ませ ん でし た 。 メール の 例 が とても 分かり やすかっ た です 。 あと 、 小 テスト が あっ た ので よかっ た です 。 AI の 取り掛かり に は 良い セミナー でし た 。 満足 です 。 AI ソフト の 使い方 や パラメータ の 意味 が 理解 でき た ので 活用 し やすく なり まし た 。 ただ 、 もう少し 数学 的 な 説明 が ある と 理解 し やすい よう に 思い ます 。 独学 で は 学習 の 方向 性 が 正しい の か 自分 で は 判ら ない ので 、 この セミナー が 参考 に なっ て よかっ た と 思い ます 。 AI について 、 全く の ド 素人 だっ た 私 に も 、 とても 分かり やすく 噛み砕い て 説明 し て くださる ので 、 概ね 理解 する こと が でき まし た 。 また 実際 に 操作 を 体験 する こと が でき 、 AI の 仕組み を より 深く 学ぶ こと が でき まし た 。 ありがとう ござい まし た 。 AI が こんなにも 身近 に 感じ られる よう に なる と は 思っ て なかっ た ので 感動 し まし た ！ 今後 AI を アプリ 利用 する よう な プログラム を 作る セミナー を 実施 予定 と の こと だっ た ので 、 また 機会 が あれ ば 受講 し たい と 思い ます 。 ありがとう ござい まし た ！ 電気 系 で 情報処理 の 知識 が 少なく 理解 できる か どう か 不安 だっ た が 、 平易 な 説明 だっ た ので 分かり やすかっ た 。 さらに 、 CNN の 体験 を通じて 特徴 量 を 強調 さ せ て いく モデル について の 概要 を 把握 でき た と 思う 。 初心者 で も わかり やすい セミナー で 安心 し まし た 。 意外と 簡単 に AI が 作れる こと に 驚き まし た 。 AI を 使っ た スマホアプリ を 作る セミナー など が あれ ば 参加 し たい です 。 入口 として 使い方 が わかる こと が 非常 に 良かっ た 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "blog = open(\"corpora/blog.txt\", \"r\")\n",
    "txt = blog.read()\n",
    "\n",
    "\n",
    "\n",
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger ('-Owakati')\n",
    "result = tagger.parse(txt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名詞 ＝ \n",
      " ['こころ', '夏目', '漱石', '私', 'わたくし', '人', '先生', 'ここ', '先生', '本名', 'これ', '世間', '憚', 'ば', '遠慮', '方', '私', '自然', '私', '人', '記憶', 'ごと', '先生', '筆', '心持', '事', '頭文字', 'かしら', '気', '私', '先生', '知り合い', 'の', '鎌倉', 'かまくら', '時', '私', '書生', '暑中', '休暇', '利用', '海水浴', '友達', '端書', 'はがき', '私', '金', '工面', '事', '私']\n",
      "動詞 ＝ \n",
      " ['呼ん', 'い', '書く', '打ち明け', 'いう', '呼び', '起す', 'いい', 'なる', '執', '使う', 'なら', 'なっ', 'し', '行っ', '来い', '受け取っ', 'くめ', 'し', '出掛ける', 'し', 'ち', '費やし', '着い', '呼び寄せ', '帰れ', '受け取っ', '断っ', 'あっ', '信じ', 'かね', 'いる', 'し', 'いら', 'れ', 'い', 'いう', 'する', '過ぎ', '気に入ら', '帰る', '避け', '遊ん', 'い', '見せ', 'しよ', 'し', '分ら', 'すれ', '帰る']\n",
      "形容詞 ＝ \n",
      " ['かる', 'よそよそしい', '若々しい', 'ない', 'ない', '若', 'いい', '固', 'よし', 'よい', 'ない', '長い', '近い', '古い', 'くす', '黒い', '黒い', 'ない', '白い', 'ぽ', 'く', '長い', '小高い', '珍しく', 'とお', '小さく', 'おも', 'ない', '騒がしい', '浅い', '深', 'く', '有難う', '広い', 'なかっ', '強い', '強い', '快く', '長く', 'ない', '悪く', '広い', 'くちく', '若い', '暗', '濃', '物足りない', 'よく', '若かっ', '若い']\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    return sentence.rstrip()\n",
    "\n",
    "\n",
    "path ='corpora/kokoro.txt'\n",
    "\n",
    "with open(path) as fd:\n",
    "        nouns = []\n",
    "        verbs = []\n",
    "        adjs = []\n",
    "\n",
    "        for sentence in map(preprocessing, fd):\n",
    "            for chunk in tagger.parse(sentence).splitlines()[:-1]:\n",
    "                (surface, feature) = chunk.split('\\t')\n",
    "                pos = feature.split(\",\")[0]\n",
    "                if pos =='名詞':           \n",
    "                    nouns.append(surface)\n",
    "                elif pos == '動詞':\n",
    "                    verbs.append(surface)\n",
    "                elif pos == '形容詞':\n",
    "                    adjs.append(surface)\n",
    "                                   \n",
    "print ('名詞 ＝ \\n',nouns[:50])\n",
    "print ('動詞 ＝ \\n',verbs[:50])\n",
    "print ('形容詞 ＝ \\n', adjs[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/Salinger/items/529a77f2ceeb39998665\n",
    "\n",
    "MeCabによる形態素解析結果の出力：\n",
    "以下のコードではうまく処理ができません。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeCabによる形態素解析結果の出力：その１\n",
    "ソフトをアプデートしたら、parseToNode() の処理が相当変化しています。その入力用のソースはstr形式になりました。\n",
    "parseToNode()は利用しないほうが無難です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./corpora/kokoro.txt\"\n",
    "bindata = open(path, \"rb\").read()\n",
    "text = bindata.decode(\"utf-8\")\n",
    "\n",
    "import MeCab\n",
    "\n",
    "#MECAB_MODE = 'mecabrc'                                                                                                                                                   \n",
    "tagger = MeCab.Tagger('mecabrc')\n",
    "tagger.parseToNode('')\n",
    "\n",
    "#tagger.parse(\"\") #文字列がGCされるのを防ぐ\n",
    " # str 型じゃないと動作がおかしくなるので str 型に変換\n",
    "node = tagger.parseToNode(text)\n",
    "\n",
    "words = []\n",
    "nouns = []\n",
    "verbs = []\n",
    "adjs = []\n",
    "while node:\n",
    "        pos = node.feature.split(\",\")[0] #品詞を取得\n",
    "        word = node.surface #単語を取得\n",
    "        if pos == \"名詞\":\n",
    "            nouns.append(word) \n",
    "        elif pos == \"動詞\":\n",
    "            verbs.append(word)\n",
    "        elif pos == \"形容詞\":\n",
    "            adjs.append(word)\n",
    "        words.append(word)\n",
    "        node = node.next #次の単語に進める\n",
    "words_dict = {\n",
    "        \"text\": words[1:-1], # 最初と最後には空文字列が入るので除去                                                                                                \n",
    "        \"nouns\": nouns,\n",
    "        \"verbs\": verbs,\n",
    "        \"adjs\": adjs\n",
    "        }\n",
    "\n",
    "print (\"文: \\n\", words[:80])\n",
    "print (\"名詞: \\n\", nouns[:50])\n",
    "print (\"動詞: \\n\", verbs[:50])\n",
    "print (\"形容詞: \\n\", adjs[:50])\n",
    "#print (\"text:\", \",\".join(words_dict['text']))\n",
    "#print (\"Nouns: \\n\", \",\".join(words_dict['nouns']))\n",
    "#print (\"Verbs: \\n\", \",\".join(words_dict['verbs']))\n",
    "#print (\"Adjs: \\n\", \",\".join(words_dict['adjs']))\n",
    "\n",
    "#from nltk.text import Text\n",
    "\n",
    "#souseki = Text(text)\n",
    "#print (\"concordance of '私'---\")#\n",
    "#souseki.concordance('私') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
